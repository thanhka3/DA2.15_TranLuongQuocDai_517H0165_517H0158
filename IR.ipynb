{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from underthesea import word_tokenize\n",
    "from rank_bm25 import BM25Okapi, BM25Plus\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data.txt',encoding='utf-8').read().split(\"\\n\")\n",
    "data = []\n",
    "for line in file:\n",
    "    if re.search(\"^.*\\.\", line) or re.search(\"^.*\\)\", line):\n",
    "        data.append(line.lower())\n",
    "\n",
    "stopwords = open('../stopwords.txt', encoding='utf-8').read().split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopwords(sentence):\n",
    "  words = word_tokenize(sentence)\n",
    "  word = [w.lower() for w in words if w not in (stopwords)]\n",
    "  sentence_clean = \" \".join(word)\n",
    "  \n",
    "  return sentence_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25okapi_search(tokenized_query, bm25, corpus, n_results = 1):\n",
    "    \"\"\"\n",
    "    Function that takes a tokenized query and prints the first 100 words of the \n",
    "    n_results most relevant results found in the corpus, based on the BM25\n",
    "    method.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    @param tokenized_query: list, array-like\n",
    "        A valid list containing the tokenized query.\n",
    "    @param bm25: BM25 object,\n",
    "        A valid object of type BM25 (BM25Okapi or BM25Plus) from the library\n",
    "        `rank-bm25`, initialized with a valid corpus.\n",
    "    @param corpus: list, array-like\n",
    "        A valid list containing the corpus from which the BM25 object has been \n",
    "        initialized. As returned from function read_corpus().\n",
    "    @param n_results: int, default = 1\n",
    "        The number of top results to print.\n",
    "    \"\"\"\n",
    "    \n",
    "    # We skip checking validity of arguments for now... We assume the user \n",
    "    # knows what they're doing.\n",
    "    \n",
    "    # Get top results for the query\n",
    "    top_results = bm25.get_top_n(tokenized_query, corpus, n = n_results)\n",
    "    top_results_100words = [' '.join(top_result.split(' ')) \n",
    "                             for top_result in top_results]\n",
    "    \n",
    "    return top_results_100words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = [word_tokenize(doc) for doc in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = BM25Okapi(tokenized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to load\n",
    "with open('bm25result', 'wb') as bm25result_file:\n",
    "    pickle.dump(bm25, bm25result_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to read bm25 object\n",
    "with open('bm25result', 'rb') as bm25result_file:\n",
    "    bm25result = pickle.load(bm25result_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bộ luật dân sự\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['đối với giao dịch dân sự được xác lập trước ngày bộ luật này có hiệu lực thì việc áp dụng pháp luật được quy định như sau: giao dịch dân sự chưa được thực hiện mà có nội dung, hình thức khác với quy định của bộ luật này thì chủ thể giao dịch tiếp tục thực hiện theo quy định của bộ luật dân sự số 33/2005/qh11 và các văn bản quy phạm pháp luật quy định chi tiết bộ luật dân sự số 33/2005/qh11, trừ trường hợp các bên của giao dịch dân sự có thỏa thuận về việc sửa đổi, bổ sung nội dung, hình thức của giao dịch để phù hợp với bộ luật này và để áp dụng quy định của bộ luật này, giao dịch dân sự đang được thực hiện mà có nội dung, hình thức khác với quy định của bộ luật này thì áp dụng quy định của bộ luật dân sự số 33/2005/qh11 và các văn bản quy phạm pháp luật quy định chi tiết bộ luật dân sự số 33/2005/qh11, giao dịch dân sự chưa được thực hiện hoặc đang được thực hiện mà có nội dung và hình thức phù hợp với quy định của bộ luật này thì áp dụng quy định của bộ luật này, giao dịch dân sự được thực hiện xong trước ngày bộ luật này có hiệu lực mà có tranh chấp thì áp dụng quy định của bộ luật dân sự số 33/2005/qh11 và các văn bản quy phạm pháp luật quy định chi tiết bộ luật dân sự số 33/2005/qh11 để giải quyết, thời hiệu được áp dụng theo quy định của bộ luật này ; điều 688 khoản 1.',\n",
       " 'bộ luật này là luật chung điều chỉnh các quan hệ dân sự điều 4 khoản 1. ',\n",
       " 'giao dịch dân sự không có một trong các điều kiện được quy định tại điều 117 của bộ luật này thì vô hiệu, trừ trường hợp bộ luật này có quy định khác ; điều 122.',\n",
       " 'đối với giao dịch dân sự quy định tại điều 123 và điều 124 của bộ luật này thì thời hiệu yêu cầu tòa án tuyên bố giao dịch dân sự vô hiệu không bị hạn chế ; điều 132 khoản 3.  ',\n",
       " 'không hạn chế năng lực pháp luật dân sự của cá nhân năng lực pháp luật dân sự của cá nhân không bị hạn chế, trừ trường hợp bộ luật này, luật khác có liên quan quy định khác ; điều 18. ']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"bộ luật dân sự là gì ?\"\n",
    "print(removeStopwords(query))\n",
    "tokenized_query = word_tokenize(removeStopwords(query))\n",
    "\n",
    "bm25okapi_search(tokenized_query = tokenized_query,\n",
    "                 bm25 = bm25, \n",
    "                 corpus = data,\n",
    "                 n_results = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input question:  Hiệu lực thi hành bộ luật dân sự là khi nào ?\n",
      "Cleaned question:  hiệu lực thi hành bộ luật dân sự nào\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['bộ luật này có hiệu lực thi hành từ ngày 01 tháng 01 năm 2017, bộ luật dân sự số 33/2005/qh11 hết hiệu lực kể từ ngày bộ luật này có hiệu lực, bộ luật này đã được quốc hội nước cộng hòa xã hội chủ nghĩa việt nam khóa xiii, kỳ họp thứ 10 thông qua ngày 24 tháng 11 năm 2015 ; điều 689.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Hiệu lực thi hành bộ luật dân sự là khi nào ?\"\n",
    "print(\"input question: \", query)\n",
    "print(\"Cleaned question: \",removeStopwords(query))\n",
    "tokenized_query = word_tokenize(removeStopwords(query))\n",
    "bm25okapi_search(tokenized_query = tokenized_query,\n",
    "                 bm25 = bm25, \n",
    "                 corpus = data,\n",
    "                 n_results = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function read file test\n",
    "def read_data_test(filePath):\n",
    "    f = open(filePath,encoding='utf-8')\n",
    "    fileRead = json.load(f)\n",
    "    question = []\n",
    "    answer = []\n",
    "    for object in fileRead:\n",
    "        question.append(object[\"question\"].lower())\n",
    "        answer.append(object[\"answer\"].lower())\n",
    "    dataset = {\n",
    "    \"question\": question,\n",
    "    \"answer\": answer\n",
    "    }\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get score predict with bleu\n",
    "test_data = read_data_test(\"./QA_data/qa_test.json\")\n",
    "test_data = Dataset.from_dict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = []\n",
    "for i in test_data[\"question\"]:\n",
    "    tokenized_query = word_tokenize(removeStopwords(i))\n",
    "    result = bm25okapi_search(tokenized_query = tokenized_query,\n",
    "                 bm25 = bm25, \n",
    "                 corpus = data,\n",
    "                 n_results = 1)\n",
    "    predicts.append(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "#function to get score of results\n",
    "def getScore(ref, candi):\n",
    "    score = sentence_bleu(ref, candi)\n",
    "    return float('{:.4f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference= []\n",
    "for i in test_data[\"answer\"]:\n",
    "    reference.append(i.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in predicts:\n",
    "    scores.append(getScore(reference,i[0].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42416091954023005"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average = sum(scores)/len(scores)\n",
    "average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score(precision=0.265196193452529, recall=0.8852439869308493, fmeasure=0.3662911535955582)\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "rouge = datasets.load_metric(\"rouge\")\n",
    "rouge_output = rouge.compute(predictions=predicts, references=test_data[\"answer\"], rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
    "\n",
    "print(rouge_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
