{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from underthesea import word_tokenize\n",
    "from rank_bm25 import BM25Okapi, BM25Plus\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data.txt',encoding='utf-8').read().split(\"\\n\")\n",
    "data = []\n",
    "for line in file:\n",
    "    if re.search(\"^.*\\.\", line) or re.search(\"^.*\\)\", line):\n",
    "        data.append(line.lower())\n",
    "\n",
    "stopwords = open('../stopwords.txt', encoding='utf-8').read().split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopwords(sentence):\n",
    "  words = word_tokenize(sentence)\n",
    "  word = [w.lower() for w in words if w not in (stopwords)]\n",
    "  sentence_clean = \" \".join(word)\n",
    "  \n",
    "  return sentence_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25okapi_search(tokenized_query, bm25, corpus, n_results = 1):\n",
    "    \"\"\"\n",
    "    Function that takes a tokenized query and prints the first 100 words of the \n",
    "    n_results most relevant results found in the corpus, based on the BM25\n",
    "    method.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    @param tokenized_query: list, array-like\n",
    "        A valid list containing the tokenized query.\n",
    "    @param bm25: BM25 object,\n",
    "        A valid object of type BM25 (BM25Okapi or BM25Plus) from the library\n",
    "        `rank-bm25`, initialized with a valid corpus.\n",
    "    @param corpus: list, array-like\n",
    "        A valid list containing the corpus from which the BM25 object has been \n",
    "        initialized. As returned from function read_corpus().\n",
    "    @param n_results: int, default = 1\n",
    "        The number of top results to print.\n",
    "    \"\"\"\n",
    "    \n",
    "    # We skip checking validity of arguments for now... We assume the user \n",
    "    # knows what they're doing.\n",
    "    \n",
    "    # Get top results for the query\n",
    "    top_results = bm25.get_top_n(tokenized_query, corpus, n = n_results)\n",
    "    top_results_100words = [' '.join(top_result.split(' ')) \n",
    "                             for top_result in top_results]\n",
    "    \n",
    "    return top_results_100words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = [word_tokenize(doc) for doc in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = BM25Okapi(tokenized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to load\n",
    "with open('bm25result', 'wb') as bm25result_file:\n",
    "    pickle.dump(bm25, bm25result_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to read bm25 object\n",
    "with open('bm25result', 'rb') as bm25result_file:\n",
    "    bm25result = pickle.load(bm25result_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b·ªô lu·∫≠t d√¢n s·ª±\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ƒë·ªëi v·ªõi giao d·ªãch d√¢n s·ª± ƒë∆∞·ª£c x√°c l·∫≠p tr∆∞·ªõc ng√†y b·ªô lu·∫≠t n√†y c√≥ hi·ªáu l·ª±c th√¨ vi·ªác √°p d·ª•ng ph√°p lu·∫≠t ƒë∆∞·ª£c quy ƒë·ªãnh nh∆∞ sau: giao d·ªãch d√¢n s·ª± ch∆∞a ƒë∆∞·ª£c th·ª±c hi·ªán m√† c√≥ n·ªôi dung, h√¨nh th·ª©c kh√°c v·ªõi quy ƒë·ªãnh c·ªßa b·ªô lu·∫≠t n√†y th√¨ ch·ªß th·ªÉ giao d·ªãch ti·∫øp t·ª•c th·ª±c hi·ªán theo quy ƒë·ªãnh c·ªßa b·ªô lu·∫≠t d√¢n s·ª± s·ªë 33/2005/qh11 v√† c√°c vƒÉn b·∫£n quy ph·∫°m ph√°p lu·∫≠t quy ƒë·ªãnh chi ti·∫øt b·ªô lu·∫≠t d√¢n s·ª± s·ªë 33/2005/qh11, tr·ª´ tr∆∞·ªùng h·ª£p c√°c b√™n c·ªßa giao d·ªãch d√¢n s·ª± c√≥ th·ªèa thu·∫≠n v·ªÅ vi·ªác s·ª≠a ƒë·ªïi, b·ªï sung n·ªôi dung, h√¨nh th·ª©c c·ªßa giao d·ªãch ƒë·ªÉ ph√π h·ª£p v·ªõi b·ªô lu·∫≠t n√†y v√† ƒë·ªÉ √°p d·ª•ng quy ƒë·ªãnh c·ªßa b·ªô lu·∫≠t n√†y, giao d·ªãch d√¢n s·ª± ƒëang ƒë∆∞·ª£c th·ª±c hi·ªán m√† c√≥ n·ªôi dung, h√¨nh th·ª©c kh√°c v·ªõi quy ƒë·ªãnh c·ªßa b·ªô lu·∫≠t n√†y th√¨ √°p d·ª•ng quy ƒë·ªãnh c·ªßa b·ªô lu·∫≠t d√¢n s·ª± s·ªë 33/2005/qh11 v√† c√°c vƒÉn b·∫£n quy ph·∫°m ph√°p lu·∫≠t quy ƒë·ªãnh chi ti·∫øt b·ªô lu·∫≠t d√¢n s·ª± s·ªë 33/2005/qh11, giao d·ªãch d√¢n s·ª± ch∆∞a ƒë∆∞·ª£c th·ª±c hi·ªán ho·∫∑c ƒëang ƒë∆∞·ª£c th·ª±c hi·ªán m√† c√≥ n·ªôi dung v√† h√¨nh th·ª©c ph√π h·ª£p v·ªõi quy ƒë·ªãnh c·ªßa b·ªô lu·∫≠t n√†y th√¨ √°p d·ª•ng quy ƒë·ªãnh c·ªßa b·ªô lu·∫≠t n√†y, giao d·ªãch d√¢n s·ª± ƒë∆∞·ª£c th·ª±c hi·ªán xong tr∆∞·ªõc ng√†y b·ªô lu·∫≠t n√†y c√≥ hi·ªáu l·ª±c m√† c√≥ tranh ch·∫•p th√¨ √°p d·ª•ng quy ƒë·ªãnh c·ªßa b·ªô lu·∫≠t d√¢n s·ª± s·ªë 33/2005/qh11 v√† c√°c vƒÉn b·∫£n quy ph·∫°m ph√°p lu·∫≠t quy ƒë·ªãnh chi ti·∫øt b·ªô lu·∫≠t d√¢n s·ª± s·ªë 33/2005/qh11 ƒë·ªÉ gi·∫£i quy·∫øt, th·ªùi hi·ªáu ƒë∆∞·ª£c √°p d·ª•ng theo quy ƒë·ªãnh c·ªßa b·ªô lu·∫≠t n√†y ; ƒëi·ªÅu 688 kho·∫£n 1.',\n",
       " 'b·ªô lu·∫≠t n√†y l√† lu·∫≠t chung ƒëi·ªÅu ch·ªânh c√°c quan h·ªá d√¢n s·ª± ƒëi·ªÅu 4 kho·∫£n 1. ',\n",
       " 'giao d·ªãch d√¢n s·ª± kh√¥ng c√≥ m·ªôt trong c√°c ƒëi·ªÅu ki·ªán ƒë∆∞·ª£c quy ƒë·ªãnh t·∫°i ƒëi·ªÅu 117 c·ªßa b·ªô lu·∫≠t n√†y th√¨ v√¥ hi·ªáu, tr·ª´ tr∆∞·ªùng h·ª£p b·ªô lu·∫≠t n√†y c√≥ quy ƒë·ªãnh kh√°c ; ƒëi·ªÅu 122.',\n",
       " 'ƒë·ªëi v·ªõi giao d·ªãch d√¢n s·ª± quy ƒë·ªãnh t·∫°i ƒëi·ªÅu 123 v√† ƒëi·ªÅu 124 c·ªßa b·ªô lu·∫≠t n√†y th√¨ th·ªùi hi·ªáu y√™u c·∫ßu t√≤a √°n tuy√™n b·ªë giao d·ªãch d√¢n s·ª± v√¥ hi·ªáu kh√¥ng b·ªã h·∫°n ch·∫ø ; ƒëi·ªÅu 132 kho·∫£n 3.  ',\n",
       " 'kh√¥ng h·∫°n ch·∫ø nƒÉng l·ª±c ph√°p lu·∫≠t d√¢n s·ª± c·ªßa c√° nh√¢n nƒÉng l·ª±c ph√°p lu·∫≠t d√¢n s·ª± c·ªßa c√° nh√¢n kh√¥ng b·ªã h·∫°n ch·∫ø, tr·ª´ tr∆∞·ªùng h·ª£p b·ªô lu·∫≠t n√†y, lu·∫≠t kh√°c c√≥ li√™n quan quy ƒë·ªãnh kh√°c ; ƒëi·ªÅu 18. ']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"b·ªô lu·∫≠t d√¢n s·ª± l√† g√¨ ?\"\n",
    "print(removeStopwords(query))\n",
    "tokenized_query = word_tokenize(removeStopwords(query))\n",
    "\n",
    "bm25okapi_search(tokenized_query = tokenized_query,\n",
    "                 bm25 = bm25, \n",
    "                 corpus = data,\n",
    "                 n_results = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input question:  Hi·ªáu l·ª±c thi h√†nh b·ªô lu·∫≠t d√¢n s·ª± l√† khi n√†o ?\n",
      "Cleaned question:  hi·ªáu l·ª±c thi h√†nh b·ªô lu·∫≠t d√¢n s·ª± n√†o\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['b·ªô lu·∫≠t n√†y c√≥ hi·ªáu l·ª±c thi h√†nh t·ª´ ng√†y 01 th√°ng 01 nƒÉm 2017, b·ªô lu·∫≠t d√¢n s·ª± s·ªë 33/2005/qh11 h·∫øt hi·ªáu l·ª±c k·ªÉ t·ª´ ng√†y b·ªô lu·∫≠t n√†y c√≥ hi·ªáu l·ª±c, b·ªô lu·∫≠t n√†y ƒë√£ ƒë∆∞·ª£c qu·ªëc h·ªôi n∆∞·ªõc c·ªông h√≤a x√£ h·ªôi ch·ªß nghƒ©a vi·ªát nam kh√≥a xiii, k·ª≥ h·ªçp th·ª© 10 th√¥ng qua ng√†y 24 th√°ng 11 nƒÉm 2015 ; ƒëi·ªÅu 689.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Hi·ªáu l·ª±c thi h√†nh b·ªô lu·∫≠t d√¢n s·ª± l√† khi n√†o ?\"\n",
    "print(\"input question: \", query)\n",
    "print(\"Cleaned question: \",removeStopwords(query))\n",
    "tokenized_query = word_tokenize(removeStopwords(query))\n",
    "bm25okapi_search(tokenized_query = tokenized_query,\n",
    "                 bm25 = bm25, \n",
    "                 corpus = data,\n",
    "                 n_results = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function read file test\n",
    "def read_data_test(filePath):\n",
    "    f = open(filePath,encoding='utf-8')\n",
    "    fileRead = json.load(f)\n",
    "    question = []\n",
    "    answer = []\n",
    "    for object in fileRead:\n",
    "        question.append(object[\"question\"].lower())\n",
    "        answer.append(object[\"answer\"].lower())\n",
    "    dataset = {\n",
    "    \"question\": question,\n",
    "    \"answer\": answer\n",
    "    }\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get score predict with bleu\n",
    "test_data = read_data_test(\"./QA_data/qa_test.json\")\n",
    "test_data = Dataset.from_dict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = []\n",
    "for i in test_data[\"question\"]:\n",
    "    tokenized_query = word_tokenize(removeStopwords(i))\n",
    "    result = bm25okapi_search(tokenized_query = tokenized_query,\n",
    "                 bm25 = bm25, \n",
    "                 corpus = data,\n",
    "                 n_results = 1)\n",
    "    predicts.append(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "#function to get score of results\n",
    "def getScore(ref, candi):\n",
    "    score = sentence_bleu(ref, candi)\n",
    "    return float('{:.4f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference= []\n",
    "for i in test_data[\"answer\"]:\n",
    "    reference.append(i.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in predicts:\n",
    "    scores.append(getScore(reference,i[0].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42416091954023005"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average = sum(scores)/len(scores)\n",
    "average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score(precision=0.265196193452529, recall=0.8852439869308493, fmeasure=0.3662911535955582)\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "rouge = datasets.load_metric(\"rouge\")\n",
    "rouge_output = rouge.compute(predictions=predicts, references=test_data[\"answer\"], rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
    "\n",
    "print(rouge_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
